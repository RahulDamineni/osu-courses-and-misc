{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satya Phani Rahul Damineni (933-922-122)\n",
    "\n",
    "## Need for pre-processing data\n",
    "\n",
    "### All words are lower-cased\n",
    "* For sentiment classification task, casing of word may not matter significantly to determine sentiment of the sentence\n",
    "* So, by converting everything to an uniform case, we are making the modeling task easy by telling the algorithm that either case is semantically same\n",
    "\n",
    "### Punctuation became separate words\n",
    "* The first step for NLP is to convert word symbols into numerical vectors so that modeling would be possible\n",
    "* If we leave punctuations with the adjoining word, it will be interpreted as a different token (word) – this is semantically inconsistent\n",
    "\n",
    "\n",
    "### Verb contractions are split into their component morphemes\n",
    "* This is data augmentation step too. We want our model to see you'll as you + 'll so that it can use its understanding (obtained during training) about \"you\" and \"'ll\" than seeing it as a new word and eventually deriving this rule (if at all) during training. \n",
    "* In general, all fixed rules (syntactic) about the data should be made aware to the model to make its job of deriving patterns easy. In this case, we are imposing such rules on the data and making sure the model never have to learn them while training. \n",
    "\n",
    "### Quotes are re-written\n",
    "* Same as above.\n",
    "* As long as you consistently map quotes to a new (rare) character, you don't exactly need to use forward & backward quotes. The model should be able to make out a pattern from the data it was given. \n",
    "\n",
    "\n",
    "### Spanish reviews were removed.\n",
    "* Since the quantity is small, there will be conflicting symbols to the same semantic token – this can slow down the learning algorithm if not throws it off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Perceptron Baseline\n",
    "\n",
    "### Understanding `svector.py`\n",
    "* For each operation, we are updating values of the `svector`s data-structure `defaultdict`.\n",
    "* We do that by accessing `key`, `value` pairs of `defaultdict` and updating `value` based on the required operation (`add`, `subtract`, `scalar_multiplication`, `dot_product`) and the second arguement `b`. We retrive `value` of `key` from `b` using the `key` from the original (`self`) `original [operation] b[key]`\n",
    "* The advantange in using `defaultdict` appears when `key` value gets a default `0` instead of raising `KeyError` when it is not present in `b`\n",
    "\n",
    "### Understanding `train.py`\n",
    "* `train` initializes `W` and runs for `epoch` number of times\n",
    "* In each epoch, it retrives \"train\" raw words and their labels iteratively, converts words into a `svector`.\n",
    "* It then checks if the dot product of retrieved sentence and W yields correct label and updates `W` if it doesn't\n",
    "* It also evaluates the dev error and keeps track of best error for each epoch\n",
    "* `test` retrieves \"dev\" raw words and their labels and uses the trained W to determine how many errors happen\n",
    "* It returns the normalized error of the entire dev set for the current `W`\n",
    "* The epoch summaries and final summary would be printed\n",
    "\n",
    "### Adding bias term\n",
    "* Yes, adding bias reduced to dev error to `26.3%`\n",
    "* I added bias by adding an extra dimension (`--bias--`) and set it to `1` to all sentence vectors.\n",
    "\n",
    "### Why is bias helping on a balanced dataset? \n",
    "* Sometimes a dataset may not be linearly seperable through origin – bias term accommodates this scenario\n",
    "* Even though the dataset is balanced, depending upon the order of training data, the final model vector could be slightly misaligned causing the nearby points to be misclassified. The bias term compensates by giving slight translation (`bias = -2.0`) to avoid this – based on the order of input examples. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged Perceptron\n",
    "\n",
    "### Accuracy: `26.3%`. Averaging made dev errors consistently smooth\n",
    "\n",
    "### Training speed: It slightly slowed down training (to `1.9s`) owing to extra ops in calculating averaged model\n",
    "\n",
    "### Feature importances:\n",
    "#### 20 most negative features:\n",
    "\n",
    "```\n",
    "[('boring', -1193063.0), ('generic', -1044776.0), ('dull', -1030705.0), ('badly', -949415.0), ('routine', -937094.0), ('fails', -8915\n",
    "32.0), ('ill', -880309.0), ('too', -846307.0), ('instead', -817796.0), ('tv', -816025.0), ('attempts', -795684.0), ('unless', -794483\n",
    ".0), ('incoherent', -788491.0), ('neither', -787754.0), ('flat', -782628.0), ('seagal', -772992.0), ('problem', -770499.0), ('scatter\n",
    "ed', -767592.0), ('worst', -766857.0), ('suffers', -765722.0)]\n",
    "```\n",
    "\n",
    "#### 20 most positive features:\n",
    "```\n",
    "[('flaws', 750394.0), ('smarter', 750566.0), ('imax', 768587.0), ('delightful', 778127.0), ('powerful', 780247.0), ('open', 791666.0)\n",
    "\n",
    ", ('refreshingly', 804340.0), ('wonderful', 813079.0), ('dots', 816579.0), ('cinema', 819089.0), ('culture', 819333.0), ('pulls', 832\n",
    "015.0), ('treat', 847015.0), ('skin', 849652.0), ('french', 864314.0), ('provides', 878381.0), ('rare', 889956.0), ('unexpected', 890\n",
    "237.0), ('triumph', 906538.0), ('engrossing', 975282.0)]\n",
    "```\n",
    "\n",
    "Yes, most of them make sense. But `flaws` being the most positive feature is surprising. `Segal` seem to be a bad director, I don't recognise any of this movies.\n",
    "\n",
    "### Top 5 false positives and false negatives:\n",
    "\n",
    "#### False positives:\n",
    "```\n",
    "[\"the thing about guys like evans is this you 're never quite sure where self promotion ends and the truth begins but as you\n",
    " watch the movie , you 're too interested to care\", 'neither the funniest film that eddie murphy nor robert de niro has ever made , s\n",
    "howtime is nevertheless efficiently amusing for a good while before it collapses into exactly the kind of buddy cop comedy it set out\n",
    " to lampoon , anyway', \"even before it builds up to its insanely staged ballroom scene , in which 3000 actors appear in full regalia\n",
    ", it 's waltzed itself into the art film pantheon\", \"if i have to choose between gorgeous animation and a lame story ( like , say , treasure planet ) or so so animation and an exciting , clever story with a batch of appealing characters , i 'll take the latter every\n",
    " time\", 'carrying off a spot on scottish burr , duvall ( also a producer ) peels layers from this character that may well not have ex\n",
    "isted on paper']\n",
    "```\n",
    "\n",
    "#### False negatives:\n",
    "```\n",
    "['an atonal estrogen opera that demonizes feminism while gifting the most sympathetic male of the piece with a nice\n",
    "vomit bath at his wedding', 'mr wollter and ms seldhal give strong and convincing performances , but neither reaches into the deepest\n",
    " recesses of the character to unearth the quaking essence of passion , grief and fear', 'bravo reveals the true intent of her film by\n",
    " carefully selecting interview subjects who will construct a portrait of castro so predominantly charitable it can only be seen as propaganda', \"how much you are moved by the emotional tumult of fran ois and mich le 's relationship depends a lot on how interesting a\n",
    "nd likable you find them\", \"` in this poor remake of such a well loved classic , parker exposes the limitations of his skill and the\n",
    "basic flaws in his vision '\"]\n",
    "```\n",
    "\n",
    "These make sense too: `nevertheless efficiently amusing for a good while before it collapses into exactly the kind of buddy cop comedy it set` is a hard one to classify by assigning weights to features without realizing their context.\n",
    "\n",
    "### Caching: imroved speed to `1.7s`. This was effective. I didn't optimize what I'd be making a hash key, otherwise could have improved further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the Vocabulary\n",
    "\n",
    "### Neglecting one-count words: dev error = `25.9%`. It improved – model regularized\n",
    "\n",
    "### Update % = `10.6%` at 10th epoch: Meaning model is generalizing (towards underfitting than over fitting)\n",
    "\n",
    "### Model size = `8425` (Yes, almost halved)\n",
    "\n",
    "### Training speed = `2.1s` (without caching). Not much, I think computing dot product isn't the bottleneck.\n",
    "\n",
    "### If I neglect <=2 word counts: dev error = `26.6%`, for <=3 word counts: dev error = `27%`. Model size is shrinking though. Even thought it didn't improve, notice that it didn't cause as much damage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(textfile):\n",
    "    '''\n",
    "    Loads and returns input sentences and their labels (+ / -)\n",
    "    '''\n",
    "    with open(textfile) as in_:\n",
    "        examples = in_.readlines()\n",
    "        \n",
    "    X, y = [], []\n",
    "    for ex in examples:\n",
    "        label, sent = ex.strip().split(\"\\t\")\n",
    "#         label = 1 if label == \"+\" else -1\n",
    "        \n",
    "        X.append(sent)\n",
    "        y.append(label)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = load_data(\"hw4-data/train.txt\")\n",
    "dev_X, dev_y = load_data(\"hw4-data/dev.txt\")\n",
    "test_X, _ = load_data(\"hw4-data/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set()\n",
    "with open(\"hw4-data/tokens.json\") as in_:\n",
    "    pruned_tokens = json.load(in_)\n",
    "\n",
    "tokens_index = {tk: i for i, tk in enumerate(pruned_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_normalizer(list_of_sent):\n",
    "    \n",
    "    out = np.zeros((len(list_of_sent), len(tokens_index)))\n",
    "    for sid, sent in enumerate(list_of_sent):\n",
    "        tokens = sent.split()\n",
    "        \n",
    "        for token in tokens:\n",
    "            try:\n",
    "                out[sid, tokens_index[token]] += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = input_normalizer(train_X)\n",
    "dv_X = input_normalizer(dev_X)\n",
    "ts_X = input_normalizer(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(tr_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error: 35.60%\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev error: {(1 - clf.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I quickly tried gradient boosting and it performed much worse than Avg. Perceptron.\n",
    "* The main reason for this is how the weak classifiers could have very little/ no info about the polarity all possible features that they could encounter while they are trained only on a small subset of data. \n",
    "* The strength of this algorithm is how well it can regularise but in this case it's just throwing the data away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=20000, min_df=1,\n",
       "        ngram_range=(1, 10), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "        open(\"hw4-data/train.txt\").read(),\n",
    "            open(\"hw4-data/dev.txt\").read(),\n",
    "                open(\"hw4-data/test.txt\").read()\n",
    "]\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    analyzer='word',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 10),\n",
    "    max_features=20000)\n",
    "word_vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = word_vectorizer.transform(train_X)\n",
    "dv_X = word_vectorizer.transform(dev_X)\n",
    "ts_X = word_vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(tr_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error (Gradient Boosting Classifier): 39.30%\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev error (Gradient Boosting Classifier): {(1 - gbc.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsp/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(tr_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error (Logistic Regression): 27.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev error (Logistic Regression): {(1 - lr.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv = LogisticRegressionCV(cv=5, max_iter=500).fit(tr_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error (Logistic Regression): 26.50%\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev error (Logistic Regression): {(1 - lrcv.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "* Logistic Regression \n",
    "* Dev error = `25.7%`\n",
    "* Params = `{'C': 4.281332398719396, 'penalty': 'l2', 'solver': 'liblinear'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['liblinear']\n",
    "}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(tr_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error (Logistic Regression): 25.70%\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev error (Logistic Regression): {(1 - best_clf.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4.281332398719396, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_clf.predict(ts_X).tolist()\n",
    "output = []\n",
    "for sent, pred in zip(*[test_X, predictions]):\n",
    "    output.append(pred + \"\\t\" + sent)\n",
    "    \n",
    "with open(\"predictions.y\", \"w+\") as out:\n",
    "    out.write(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error (SGD Regression): 33.30%\n"
     ]
    }
   ],
   "source": [
    "sgdc = make_pipeline(\n",
    "        StandardScaler(with_mean=False),\n",
    "        SGDClassifier(max_iter=1000, tol=1e-3)\n",
    ").fit(tr_X, train_y)\n",
    "print(f'Dev error (SGD Regression): {(1 - sgdc.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev error (SVM Classifer): 30.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsp/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svmc = make_pipeline(StandardScaler(with_mean=False),\n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "svmc.fit(tr_X, train_y)\n",
    "print(f'Dev error (SVM Classifer): {(1 - svmc.score(dv_X, dev_y)) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debriefing\n",
    "\n",
    "1. `6 hours`\n",
    "2. Moderate \n",
    "3. Alone\n",
    "4. 80%\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit2e16e028ce8b4007b970cece9146d16d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
